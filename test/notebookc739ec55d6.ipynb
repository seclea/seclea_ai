{
 "metadata": {
  "language_info": {
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.6.4",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Goal\n",
    "The goal is to use a simple model to classify x-ray images in Keras, the notebook how to use the ```flow_from_dataframe``` to deal with messier datasets"
   ],
   "metadata": {
    "_cell_guid": "19ff9d0b-d32d-4325-a19f-2ccbfa7d2dff",
    "_uuid": "9206c5863724e1af01281071e0f0ee5109ef431b",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "_cell_guid": "f42f6560-edf0-4efb-85a6-6e945e50895b",
    "_uuid": "3300a1edbf2e8122d88093998eb503a6fab8a719",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_xray_df = pd.read_csv('../input/Data_Entry_2017.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('..', 'input', 'images*', '*', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\n",
    "all_xray_df.sample(3)"
   ],
   "metadata": {
    "_cell_guid": "9a342cdc-0823-490d-9a3a-a53fb7c33727",
    "_uuid": "fe804e7c294e2d290e27b037bf1ba56177abab70",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/Data_Entry_2017.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m all_xray_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../input/Data_Entry_2017.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m all_image_paths \u001B[38;5;241m=\u001B[39m {os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(x): x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \n\u001B[1;32m      3\u001B[0m                    glob(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimages*\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*.png\u001B[39m\u001B[38;5;124m'\u001B[39m))}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mScans found:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mlen\u001B[39m(all_image_paths), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, Total Headers\u001B[39m\u001B[38;5;124m'\u001B[39m, all_xray_df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/pycharm_projects/seclea/seclea_ai/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pycharm_projects/seclea/seclea_ai/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pycharm_projects/seclea/seclea_ai/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/pycharm_projects/seclea/seclea_ai/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pycharm_projects/seclea/seclea_ai/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/pycharm_projects/seclea/seclea_ai/venv/lib/python3.8/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../input/Data_Entry_2017.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Labels\n",
    "Here we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels"
   ],
   "metadata": {
    "_cell_guid": "0d674a43-170f-4ca6-a9b4-edc64ab89c35",
    "_uuid": "9a1669750b7cffcae1b7a2eb4307b85472dff192",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ],
   "metadata": {
    "_cell_guid": "d75ed03e-986d-4f3f-81af-c910d194f390",
    "_uuid": "0c5123f65edf349f8ad2e5c5f55ac484d974f5c7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
    "all_xray_df.sample(3)"
   ],
   "metadata": {
    "_cell_guid": "a9ff3a04-254d-4667-b0a3-869bbd92b08b",
    "_uuid": "78b4425b0a8932bb33864b5a3712611004687a48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean categories\n",
    "Since we have too many categories, we can prune a few out by taking the ones with only a few examples"
   ],
   "metadata": {
    "_cell_guid": "05b6c7d9-4869-40b5-a70b-53957c69f021",
    "_uuid": "64653f9f57d3a5b952f1f1a709eb70ca38761a0d",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# keep at least 1000 cases\n",
    "MIN_CASES = 1000\n",
    "all_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES]\n",
    "print('Clean Labels ({})'.format(len(all_labels)), \n",
    "      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])"
   ],
   "metadata": {
    "_cell_guid": "dd273e26-63ab-4d76-925d-9c1c2c1ba69c",
    "_uuid": "9f368f9ea8947d8fc1dacf3988c58b6a2bf5fffc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n",
    "# weight is 0.1 + number of findings\n",
    "sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\n",
    "sample_weights /= sample_weights.sum()\n",
    "all_xray_df = all_xray_df.sample(40000, weights=sample_weights)\n",
    "\n",
    "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ],
   "metadata": {
    "_cell_guid": "01478f44-5beb-4a6c-aa27-77db4b9abf10",
    "_uuid": "cf071cfa49f2886d9795cdf6067a8afdafd6f458",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "ax1.set_xticklabels(all_labels, rotation = 90)\n",
    "ax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n",
    "_ = ax1.set_ylabel('Frequency (%)')"
   ],
   "metadata": {
    "_cell_guid": "277caf38-f13d-4939-9eef-55efaf73020e",
    "_uuid": "cb9f18a64740580e1c541b8631d45720be5f36fe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Training Data\n",
    "Here we split the data into training and validation sets and create a single vector (disease_vec) with the 0/1 outputs for the disease status (what the model will try and predict)"
   ],
   "metadata": {
    "_cell_guid": "a1367d63-4c7b-4e47-b19f-9a26d1f89476",
    "_uuid": "6ed6489bbd618fb419ceca2bbd8c300694f1d4ed",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])"
   ],
   "metadata": {
    "_cell_guid": "185ae07c-17a2-46d3-81ca-4007e88cbf86",
    "_uuid": "6f82e5ae33e1c0fcfa33ac51a26885cb5a0e6bb1",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(all_xray_df, \n",
    "                                   test_size = 0.25, \n",
    "                                   random_state = 2018,\n",
    "                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\n",
    "print('train', train_df.shape[0], 'validation', valid_df.shape[0])"
   ],
   "metadata": {
    "_cell_guid": "5feddc96-7958-4d34-81f1-10eba94ab1b6",
    "_uuid": "8c7dc722de08243cc763d23928708f9c040bbdc6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Data Generators\n",
    "Here we make the data generators for loading and randomly transforming images"
   ],
   "metadata": {
    "_cell_guid": "7178cb8d-f220-4422-93ae-2469f0c97493",
    "_uuid": "0115346eb989e7eaeffa3643d05c654ec5ceb7c2",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "IMG_SIZE = (128, 128)\n",
    "core_idg = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=5, \n",
    "                              shear_range = 0.1,\n",
    "                              fill_mode = 'reflect',\n",
    "                              zoom_range=0.15)"
   ],
   "metadata": {
    "_cell_guid": "30eaf01b-8ec0-4407-9d25-f87ca1f48e8a",
    "_uuid": "b5e42124376584390e925a06c4cee564285e43b3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ],
   "metadata": {
    "_cell_guid": "b67dc5fa-d91b-420a-aaa7-b3991313127a",
    "_uuid": "dbb93f7f8248031563ec7042d978650c0c957c1f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_gen = flow_from_dataframe(core_idg, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'grayscale',\n",
    "                            batch_size = 32)\n",
    "\n",
    "valid_gen = flow_from_dataframe(core_idg, valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'grayscale',\n",
    "                            batch_size = 256) # we can use much larger batches for evaluation\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "test_X, test_Y = next(flow_from_dataframe(core_idg, \n",
    "                               valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'grayscale',\n",
    "                            batch_size = 1024)) # one big batch"
   ],
   "metadata": {
    "_cell_guid": "dc4d027c-f5c4-48b8-8ab6-b41971ad514f",
    "_uuid": "cc92b74f28987fee4971e60a71f74660693f4278",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n",
    "                             if n_score>0.5]))\n",
    "    c_ax.axis('off')"
   ],
   "metadata": {
    "_cell_guid": "0621048f-3d4c-4eb7-aaee-0c53f7cbf26a",
    "_uuid": "2852ef2fe07eb6d8e2caf056d1428d153afad65f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a simple model\n",
    "Here we make a simple model to train using MobileNet as a base and then adding a GAP layer (Flatten could also be added), dropout, and a fully-connected layer to calculate specific features"
   ],
   "metadata": {
    "_cell_guid": "cce3c89c-4292-4092-9317-ca066d72e354",
    "_uuid": "5b0ec78f2ffa8137dce37744f38a40782aafb54d",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "base_mobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n",
    "                                 include_top = False, weights = None)\n",
    "multi_disease_model = Sequential()\n",
    "multi_disease_model.add(base_mobilenet_model)\n",
    "multi_disease_model.add(GlobalAveragePooling2D())\n",
    "multi_disease_model.add(Dropout(0.5))\n",
    "multi_disease_model.add(Dense(512))\n",
    "multi_disease_model.add(Dropout(0.5))\n",
    "multi_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\n",
    "multi_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                           metrics = ['binary_accuracy', 'mae'])\n",
    "multi_disease_model.summary()"
   ],
   "metadata": {
    "_cell_guid": "235846d4-3ef1-4888-a276-6134ad572415",
    "_uuid": "a447f8cc7274c06555849a40881fb903aca7001a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('xray_class')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "callbacks_list = [checkpoint, early]"
   ],
   "metadata": {
    "_cell_guid": "1acd1753-dae2-440d-a9d5-f3bbebfe446f",
    "_uuid": "90a131f99bea8b77fba54024e261a97e24dfc6c1",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First Round\n",
    "Here we do a first round of training to get a few initial low hanging fruit results"
   ],
   "metadata": {
    "_cell_guid": "e5ad629e-15a3-4c96-ac74-db8077b101fe",
    "_uuid": "eba5247e4a767def4b4ead6e2f02f3c334edbbf0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "multi_disease_model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch=100,\n",
    "                                  validation_data = (test_X, test_Y), \n",
    "                                  epochs = 1, \n",
    "                                  callbacks = callbacks_list)"
   ],
   "metadata": {
    "_cell_guid": "c269083c-7617-4c16-8f96-353c1f3d8eef",
    "_uuid": "cbdfcf827510dfb3bdba6ab08ff60e21838d6987",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check Output\n",
    "Here we see how many positive examples we have of each category"
   ],
   "metadata": {
    "_cell_guid": "571df602-c0f1-4ba0-9f1e-0c9fdc10eff3",
    "_uuid": "392f3973459dcbb3fc998191baca4d047995d351",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n",
    "    print('%s: %2.2f%%' % (c_label, s_count))"
   ],
   "metadata": {
    "_cell_guid": "d9f519ef-4b4f-4bd9-8989-643b21cb8904",
    "_uuid": "308a85cd454ad05e451ec1db99432c6fe85e8e41",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
   ],
   "metadata": {
    "_cell_guid": "73a8dba1-3d8e-47ec-b945-3101ad57dcef",
    "_uuid": "0878962d872569c57b0f959751c522ae928f92e3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ROC Curves\n",
    "While a very oversimplified metric, we can show the ROC curve for each metric"
   ],
   "metadata": {
    "_cell_guid": "7a0fc649-158c-4844-9b05-f6a62214009f",
    "_uuid": "4acd4919e0ba24e2d06ef75fbb054a907a582c7a",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('barely_trained_net.png')"
   ],
   "metadata": {
    "_cell_guid": "cc076f02-0bf2-4d3f-a6ab-f192bed9e6a9",
    "_uuid": "d7168d90928d842c295c64e2446e84eb068fd391",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Continued Training\n",
    "Now we do a much longer training process to see how the results improve"
   ],
   "metadata": {
    "_cell_guid": "6c2fe734-8f87-4537-81e0-d0ce68bc2545",
    "_uuid": "8a03574bc1f2b3441538c2408fc158324d6d23df",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "multi_disease_model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch = 100,\n",
    "                                  validation_data =  (test_X, test_Y), \n",
    "                                  epochs = 5, \n",
    "                                  callbacks = callbacks_list)"
   ],
   "metadata": {
    "_cell_guid": "80b6ede7-052b-4fa2-ab97-bed0199db681",
    "_uuid": "0b35cd7ef77680d2aa180812622d89388b8fff63",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# load the best weights\n",
    "multi_disease_model.load_weights(weight_path)"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
   ],
   "metadata": {
    "_cell_guid": "97dd6d26-8d12-4aa5-8544-6bde2f8200a6",
    "_uuid": "2f358c745432e497adfac31c6d97abc8b61bd0eb",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# look at how often the algorithm predicts certain diagnoses \n",
    "for c_label, p_count, t_count in zip(all_labels, \n",
    "                                     100*np.mean(pred_Y,0), \n",
    "                                     100*np.mean(test_Y,0)):\n",
    "    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))"
   ],
   "metadata": {
    "_cell_guid": "3e754b40-8492-4f5b-a19f-a0bfd2c9b4f4",
    "_uuid": "db77f749926ac5936e860617b22713715a69157a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('trained_net.png')"
   ],
   "metadata": {
    "_cell_guid": "31990e46-1437-4945-aaa5-b31b377d6538",
    "_uuid": "a5dd26025391067cd0220b7502b193e5e095edbd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Show a few images and associated predictions"
   ],
   "metadata": {
    "_cell_guid": "a50931b1-4d88-4b2f-93f7-ad3c9de31e5c",
    "_uuid": "8ad061d6b08b9ff383f682c35c8b55f30fb560a1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\n",
    "fig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\n",
    "for (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n",
    "    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n",
    "    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n",
    "                                                                  test_Y[idx]) \n",
    "                             if n_score>0.5]\n",
    "    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n",
    "                                                                  test_Y[idx], pred_Y[idx]) \n",
    "                             if (n_score>0.5) or (p_score>0.5)]\n",
    "    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n",
    "    c_ax.axis('off')\n",
    "fig.savefig('trained_img_predictions.png')"
   ],
   "metadata": {
    "_cell_guid": "714ada59-850d-4d88-b983-2f9107f36e70",
    "_uuid": "e5191706a55a5ab8b68773d0b881aac4b020795a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "_cell_guid": "48aff5bd-c927-44ae-abd3-1de884969d3b",
    "_uuid": "817ed988ed86bc7941065eeac676d1b50cef5d0b",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "_cell_guid": "68354276-ebbb-46ca-acd6-9e8cd1354bba",
    "_uuid": "6c186e1070db679fb62a4a08e4f42a7ece925aff",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
